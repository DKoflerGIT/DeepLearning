{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library for sequential neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random as rnd\n",
    "import numpy as np\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    def __init__(self, id):\n",
    "        self.id = id\n",
    "        self.output = 0\n",
    "        self.bias = 0 if self.id[0] == 0 else round((rnd.random() - 0.5) * 5, 2) # if layer id is 0, it is an input layer\n",
    "    \n",
    "    def propagate(self, prev_layer_neurons, current_layer_weights, current_layer_activation_function):\n",
    "        net_input = 0\n",
    "\n",
    "        for n in prev_layer_neurons:\n",
    "            net_input += n.output * current_layer_weights[n.id[1]][self.id[1]]\n",
    "            \n",
    "        net_input += self.bias\n",
    "        self.output = round(self.activate(net_input, current_layer_activation_function), 2) # ToDo: How does the previous activation play a role?\n",
    "\n",
    "    def activate(self, input, activation):\n",
    "        match activation:\n",
    "            case 'identity':\n",
    "                return input\n",
    "            case 'relu':\n",
    "                return max(0, input)\n",
    "            case 'binary_step':\n",
    "                return 0 if input < 0 else 1\n",
    "            case 'sigmoid':\n",
    "                return 1 / (1 + math.exp(-input))\n",
    "            case 'tanh':\n",
    "                return math.tanh(input)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, id, num_of_neurons, activation = 'identity', prev_layer = None):\n",
    "        self.id = id\n",
    "        self.num_of_neurons = num_of_neurons\n",
    "        self.activation = activation if activation in ['identity', 'relu', 'binary_step', 'sigmoid', 'tanh'] else 'identity'\n",
    "\n",
    "        self.neurons = []\n",
    "\n",
    "        for i in range(self.num_of_neurons):\n",
    "            self.neurons.append(Neuron((self.id, i), ))\n",
    "        \n",
    "        if self.id > 0:\n",
    "            self.weights = np.zeros((prev_layer.num_of_neurons, self.num_of_neurons))\n",
    "            \n",
    "            for i in range(len(self.weights)):\n",
    "                for j in range(len(self.weights[0])):\n",
    "                    self.weights[i][j] = round(rnd.random(), 2)\n",
    "\n",
    "    def add_neuron(self):\n",
    "        self.neurons.append(Neuron((self.id, len(self.neurons))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network_Model:\n",
    "    def __init__(self, id):\n",
    "        self.id = id\n",
    "        self.layers = []\n",
    "\n",
    "    def add_layer(self, num_of_neurons, activation = 'identity'):\n",
    "        if num_of_neurons < 1:\n",
    "            print('Number of neurons has to be larger or equal to 0!')\n",
    "            return\n",
    "        \n",
    "        if activation not in ['identity', 'relu', 'binary_step', 'sigmoid', 'tanh']:\n",
    "            print(f'Activation function \"{activation}\" does not exist!')\n",
    "            return\n",
    "\n",
    "        if len(self.layers) > 0:\n",
    "            self.layers.append(Layer(len(self.layers), num_of_neurons, activation, self.layers[-1]))\n",
    "        else:\n",
    "            self.layers.append(Layer(len(self.layers), num_of_neurons, activation))\n",
    "\n",
    "    def plot_network(self):\n",
    "        for l in self.layers:\n",
    "            s = '|'\n",
    "            for n in l.neurons:\n",
    "                s += ' ' + str(n.id) + ', ' + str(n.output) + ' |'\n",
    "            print(s)\n",
    "    \n",
    "    def learn(self):\n",
    "        pass\n",
    "\n",
    "    def predict(self, input):\n",
    "        # write input to first layer\n",
    "        if len(input) != len(self.layers[0].neurons):\n",
    "            print('Not enough input values!')\n",
    "            return\n",
    "\n",
    "        for i, n in enumerate(self.layers[0].neurons):\n",
    "            n.output = input[i]\n",
    "        \n",
    "        # propagate\n",
    "        for l in self.layers:\n",
    "            if l.id == 0: continue # prevent input neurons from propagating\n",
    "\n",
    "            for n in l.neurons:\n",
    "                n.propagate(self.layers[l.id - 1].neurons, l.weights, l.activation)\n",
    "    \n",
    "        for n in self.layers[-1].neurons:\n",
    "            print(n.output)\n",
    "\n",
    "    @staticmethod\n",
    "    def normalize(input, max_value):\n",
    "        normalized = []\n",
    "        \n",
    "        for i in input:\n",
    "            normalized.append(round(i / max_value, 2))\n",
    "        return normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instanciating a network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = Network_Model(0)\n",
    "mdl.add_layer(5)\n",
    "mdl.add_layer(10, activation='relu')\n",
    "mdl.add_layer(1, activation='sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| (0, 0), 0 | (0, 1), 0 | (0, 2), 0 | (0, 3), 0 | (0, 4), 0 |\n",
      "| (1, 0), 0 | (1, 1), 0 | (1, 2), 0 | (1, 3), 0 | (1, 4), 0 | (1, 5), 0 | (1, 6), 0 | (1, 7), 0 | (1, 8), 0 | (1, 9), 0 |\n",
      "| (2, 0), 0 |\n"
     ]
    }
   ],
   "source": [
    "mdl.plot_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.89\n"
     ]
    }
   ],
   "source": [
    "input = [1, 0, 0, 0, 0]\n",
    "mdl.predict(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| (0, 0), 1 | (0, 1), 0 | (0, 2), 0 | (0, 3), 0 | (0, 4), 0 |\n",
      "| (1, 0), 1.54 | (1, 1), 0.2 | (1, 2), 0 | (1, 3), 1.1 | (1, 4), 0 | (1, 5), 1.85 | (1, 6), 0 | (1, 7), 0 | (1, 8), 0 | (1, 9), 0 |\n",
      "| (2, 0), 0.89 |\n"
     ]
    }
   ],
   "source": [
    "mdl.plot_network()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f761d2206074d82dd8e41bd143266f9d3dcf5f45b684a45cd98ca9fdc4a46ee0"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
